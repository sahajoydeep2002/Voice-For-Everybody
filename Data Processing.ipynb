{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.pipeline import make_pipeline \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import plot_confusion_matrix, confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score # Accuracy metrics \n",
    "import pickle\n",
    "\n",
    "\n",
    "from time import time\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "#####################################################################################\n",
    "# Initiate mediapipe \n",
    "\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_holistic = mp.solutions.holistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(1)  #Might need to change from 1 to a different number... default system camera is usually 0.\n",
    "## Setup mediapipe instance\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "        image.flags.writeable = False                  # Image is no longer writeable\n",
    "        results = holistic.process(image)                 # Make prediction\n",
    "        image.flags.writeable = True                   # Image is now writeable \n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks_pose = results.pose_landmarks.landmark\n",
    "            landmarks_left_hand = results.left_hand_landmarks.landmark\n",
    "            landmarks_right_hand = results.right_hand_landmarks.landmark\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "         # Render detections\n",
    "        #mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION) \n",
    "        # Draw pose connections\n",
    "        #mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) \n",
    "        # Draw left hand connections\n",
    "        mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS) \n",
    "        # Draw right hand connections  \n",
    "        mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)        \n",
    "        \n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(landmarks_pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(landmarks_left_hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(landmarks_right_hand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['class']\n",
    "#for val in range(1, 33+1):\n",
    "#    classes += ['pose_x{}'.format(val), 'pose_y{}'.format(val), 'pose_z{}'.format(val), 'pose_visibility{}'.format(val)]\n",
    "for val in range(1, 21+1):\n",
    "    classes += ['lh_x{}'.format(val), 'lh_y{}'.format(val), 'lh_z{}'.format(val)]\n",
    "for val in range(1, 21+1):\n",
    "    classes += ['rh_x{}'.format(val), 'rh_y{}'.format(val), 'rh_z{}'.format(val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('coords_4.csv', mode='w', newline='') as f:\n",
    "    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name = \"assist\" # Enter name of classification\n",
    "CSV_FILE = 'coords_4.csv'\n",
    "sequence_length = 50 # length of recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = sequence_length \n",
    "\n",
    "cap = cv2.VideoCapture(1)  #Might need to change from 1 to a different number... default system camera is usually 0.\n",
    "## Setup mediapipe instance\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            # Recolor image to RGB\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
    "            image.flags.writeable = False                  # Image is no longer writeable\n",
    "            results = holistic.process(image)                 # Make prediction\n",
    "            image.flags.writeable = True                   # Image is now writeable \n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
    "            image.flags.writeable = False\n",
    "\n",
    "\n",
    "            # Extract landmarks\n",
    "            try:\n",
    "                #pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "                lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "                rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "                #landmarks = np.concatenate([pose, lh, rh])\n",
    "                landmarks = np.concatenate([ lh, rh])\n",
    "                landmarks = np.append(class_name,landmarks)\n",
    "\n",
    "\n",
    "                #Export to CSV\n",
    "                with open(CSV_FILE, mode='a', newline='') as f:\n",
    "                    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                    csv_writer.writerow(landmarks)\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "\n",
    "\n",
    "            cv2.putText(image, 'Collecting frames for {}, Timer {}'.format(class_name, seq_len), (15,12), \n",
    "                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "             # Render detections\n",
    "            #mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION) \n",
    "            # Draw pose connections\n",
    "            #mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS) \n",
    "            # Draw left hand connections\n",
    "            mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS) \n",
    "            # Draw right hand connections  \n",
    "            mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)        \n",
    "\n",
    "            cv2.imshow('Mediapipe Feed', image)\n",
    "            seq_len = seq_len - 1\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "            if seq_len < 1:\n",
    "                break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Capstone-NLP)",
   "language": "python",
   "name": "capstone-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
